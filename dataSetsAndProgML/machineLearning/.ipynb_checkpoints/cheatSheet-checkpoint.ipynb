{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "template\n",
    "===============================================================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                 Spliting data set into train and test in python.\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "#df = pd.read_csv(path)\n",
    "#print(df.head(5))\n",
    "\n",
    "X = df\n",
    "X = X.drop(['list_price'],axis=1)\n",
    "\n",
    "y = df['list_price']\n",
    "\n",
    "# atlest X or y is required in train_test_split below\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                  R square calculation\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# R-squared calculation\n",
    "rsquared = r2_score(y_test, np.exp(y_pred))\n",
    "print(rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                  Root Mean Square Error (RMSE)\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# import packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Code starts here\n",
    "rmse = np.sqrt(mean_squared_error(y_test, np.exp(y_pred)))\n",
    "print(rmse)\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                    Mean Asolute Error\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# MAE calculation\n",
    "mae = mean_absolute_error(y_test, np.exp(y_pred))          #everytime this np.exp() is not required. It is only required when we have converted our variable earlier using log transformation\n",
    "print(mae)\n",
    "# Code ends here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "Suppose we have multiple features in X_train and only one feature in target variable y(eg SalePrice).\n",
    "Now we want to see all plots(all features individually) of X_train w.r.t. to y. \n",
    "So that we can see all plots and can see how all features are related with the target vairable(y).\n",
    "\n",
    "Below code will draw multiple graphs showing the best correlation with the target variable(feature)\n",
    "\n",
    "++ Please write which parameter we need to change\n",
    "===============================================================================================================================\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# code starts here        \n",
    "cols = X_train.columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(20,20))\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3): \n",
    "            col = cols[i*3 + j]\n",
    "            axes[i,j].set_title(col)\n",
    "            axes[i,j].scatter(X_train[col],y_train)\n",
    "            axes[i,j].set_xlabel(col)\n",
    "            axes[i,j].set_ylabel('list_price')\n",
    "        \n",
    "\n",
    "# code ends here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "\n",
    "If we want to find correlation between all features of X_train then we can use the below code to print the correlation table.\n",
    "Correlation table will help us know which independent features are highly correlated with each other.\n",
    "\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# corr code\n",
    "corr = X_train.corr()\n",
    "print(corr)\n",
    "# drop columns from X_train\n",
    "X_train.drop(['play_star_rating','val_star_rating'],axis = 1 ,inplace=True) #only used if we want to drop some columns\n",
    "\n",
    "# drop columns from X_test\n",
    "X_test.drop(['play_star_rating','val_star_rating'], axis = 1 ,inplace=True)  #only used if we want to drop some columns\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "Based on the distance between the true target y_test and predicted target y_pred, \n",
    "also known as the residual the cost function is defined.\n",
    "\n",
    "===============================================================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "          Cross validation for linearRegression---> k-fold\n",
    "          r2_score helps us to know how good is our model\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# linearRegression is an object of LinearRegression\n",
    "# newData --> All variables on X-axis\n",
    "# y --> target variable\n",
    "# cv --> number of data splits needed. 5 means, it will divide whole dataset into 5 equal parts\n",
    "#        where 4 parts will be used for training and 1 part will be used for testing\n",
    "\n",
    "r2_score = cross_val_score(linearRegression, newData, y,cv=5)\n",
    "\n",
    "# random output of r2_Score ---> array([0.87865198, 0.91763212, 0.92933032, 0.81443904, 0.89547829])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                                Ridge Regularisation--> L2 (Used for Non Linear patterns)\n",
    "                                \n",
    "                                example Equation : x**2 + y**2 = r**2    // which is the equation of circle\n",
    "                                \n",
    "                                Actaul Equation : (Yi - yPredicted)\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "parameters = {'alpha':[1e-15,1e-10,1e-8,1e-4,1e-2,1,5,10]}\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, parameters,cv=5)\n",
    "\n",
    "ridge_regressor.fit(newData,y)   \n",
    "\n",
    "\"\"\"\n",
    "Randmom output of line ridge_regressor.fit(newData,y) below:\n",
    "\n",
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.01, 1, 5, 10]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ridge_regressor.best_params_    # Will give best parameter which relates better with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                                Lasso Regularisation--> L1 (Used for Linear patterns)\n",
    "                                \n",
    "                                Equation : |x| + |y| = 2    // which is the equation line\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "parameters = {'alpha':[1e-15,1e-10,1e-8,1e-4,1e-2,1,5,10]}\n",
    "\n",
    "lasso_regressor = GridSearchCV(ridge, parameters,cv=5)\n",
    "\n",
    "lasso_regressor.fit(newData,y)  \n",
    "\n",
    "\"\"\"\n",
    "Randmom output of line lasso_regressor.fit(newData,y) below:\n",
    "\n",
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.01, 1, 5, 10]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lasso_regressor.best_params_    # Will give best parameter which relates better with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                        Violinplot looks like violin, so any data outside the plot is an outlier.\n",
    "                        It is a combination of Histogram(with the points joint which makes it look line normal distribution)\n",
    "                        and a boxplot.\n",
    "                        \n",
    "                        Can be used to plot catgorical data with the numeric one.\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.violinplot(x=tips[\"total_bill\"]) # Data Frame columns\n",
    "\n",
    "# some more examples \n",
    "\n",
    "sns.violinplot(x=\"day\", y=\"total_bill\", data=tips)\n",
    "\n",
    "sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"smoker\",data=tips, palette=\"muted\")\n",
    "\n",
    "sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"smoker\",data=tips, palette=\"muted\", split=True)\n",
    "\n",
    "sns.violinplot(x=\"time\", y=\"tip\", data=tips,order=[\"Dinner\", \"Lunch\"])\n",
    "\n",
    "sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"sex\",data=tips, palette=\"Set2\", split=True,scale=\"count\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                                   1) Count number of numeric columns in a dataframe.\n",
    "                                   2) Count number of categorical columns in a dataframe.\n",
    "                                   3) Histogram for all numeric data\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "# all numeric columns in numericDataFrame\n",
    "numericDataFrame = list(data._get_numeric_data().columns)\n",
    "\n",
    "\n",
    "# all categorical columns in categorical_feature_columns\n",
    "categorical_feature_columns = list(set(dataframe.columns) - set(dataframe._get_numeric_data().columns))\n",
    "categorical_feature_columns\n",
    "\n",
    "\n",
    "\n",
    "# *************************** Histogram for all numeric data **********************************************\n",
    "num_cols = ['age', 'bmi', 'children']\n",
    "for i in range(0,len(num_cols),2):\n",
    "    if len(num_cols) > i+1:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(121)\n",
    "        sns.distplot(data[num_cols[i]], kde=False)\n",
    "        plt.subplot(122)            \n",
    "        sns.distplot(data[num_cols[i+1]], kde=False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        sns.distplot(data[num_cols[i]], kde=False)\n",
    "\n",
    "        \n",
    "# *************************** Histogram for all numeric data with line over graph **********************************************\n",
    "\n",
    "# Above histogram code and below code is same, but below code will plot the histogram and draw continuous line over the plot,\n",
    "# which will tell us the form of distribution\n",
    "\n",
    "num_cols = ['age', 'bmi', 'children']                          # all numeric columns\n",
    "for i in range(0,len(num_cols),2):\n",
    "    if len(num_cols) > i+1:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(121)\n",
    "        sns.distplot(data[num_cols[i]],hist=True, kde=True)      # kde= true is different from the above hist code\n",
    "        plt.subplot(122)            \n",
    "        sns.distplot(data[num_cols[i+1]], hist=True,kde=True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        sns.distplot(data[num_cols[i]],hist=True, kde=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                                 Boxplot for all numeric data of independent columns.\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# BoxPlots\n",
    "\n",
    "num_cols = ['age', 'bmi', 'children']           # all numeric columns\n",
    "for i in range(0,len(num_cols),2):\n",
    "    if len(num_cols) > i+1:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(121)\n",
    "        sns.boxplot(facet, num_cols[i],data = data)    # data on RHS is the dataframe\n",
    "        plt.subplot(122)            \n",
    "        sns.boxplot(facet, num_cols[i+1],data = data)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        sns.boxplot(facet, num_cols[i],data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                              Display the count of variants inside a column.\n",
    "                              It actually displays the graph of the count of variants which is same as value_counts()\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "data['region'].value_counts()             # It will display the  counts of variants\n",
    "\n",
    "sns.countplot(data['region'])            # It will display the graph of counts of variants\n",
    "\n",
    "sns.countplot(y=data['region'])            # It will display the graph on y axis which is more readable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                            When there are only two columns so use lmplot.\n",
    "                            It will scatter plot the x and y columns and plot a line overit.\n",
    "                            Does work of linear regression. But can't be sure of accuracy\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "# data=data, data on RHS is the dataframe\n",
    "# age,bmi are the x and y columns. \n",
    "\n",
    "sns.lmplot('age', 'bmi', data=data, fit_reg=True)       # fit_reg=True, will draw the line\n",
    "\n",
    "sns.jointplot('age', 'bmi', data=data, kind='reg')      # This will also give the distribtion curve related with x and y column.\n",
    "\n",
    "sns.jointplot('age', 'bmi', data=data, kind='reg')     # Only knd is changed to 'hex' which will give shadow effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                            Work of heatmap(), will give the correlation between\n",
    "                            all the numeric data of the independent varibales \n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# cmap is the color\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(data.corr(),cmap='viridis') \n",
    "\n",
    "\n",
    "\n",
    "# Below code is the same as it is above but annot is added which will show the values of the correlation as well.\n",
    "# Use the below code mostly\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(data.corr(), annot=True,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                             *******************************************************************************\n",
    "                             \n",
    "                             Any column having more then 30% missing values we can ignore the entire column\n",
    "                             \n",
    "                             ******************************************************************************\n",
    "===============================================================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                            Nominal  : Colours eg blue, green , red etc\n",
    "                            \n",
    "                            Ordinal  : Data will follow an order. Good, Bad, Very good etc\n",
    "                            \n",
    "                            Interval : Measures which has 0, but it is also a value to be considered. \n",
    "                                       Temperature 0 does not mean that there is no temperature.\n",
    "                                       No logic 0 associated with it.\n",
    "                            \n",
    "                            Ratio    : Logic 0 exist. Division is possible\n",
    "===============================================================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================================================================================\n",
    "                             Filling the missing values with some value or mean or median or mode\n",
    "===============================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "df['preTestScore'].fillna(df['preTestScore'].mean(),inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
